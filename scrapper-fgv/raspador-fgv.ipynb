{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script para raspar dados do site da FGV\n",
    "Esse script usa os módulos Requests e BeautifulSoup para salvar as informações deste [link](http://direitosp.fgv.br/home-professor/A/all/all) em uma tabela .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando os módulos necessários\n",
    "- **Requests** para acessar a página\n",
    "- **BeatifulSoup** para copiar os elementos da página\n",
    "- **Pandas** para organizar a informação em uma tabela\n",
    "- **Time** para colocar intervalos entre cada solicitação e não sobrecarregar o site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raspando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de definir o raspador, precisamos criar um lugar para guardar as informações que salvamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# professores é uma lista. Dentro dessa lista, vamos colocar um dicionário com os dados de cada um deles.\n",
    "professores = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que são 38 páginas de dados e que a url muda de acordo com a página para o seguinte formato: */all/all/all?page=[NÚMERO_DA_PÁGINA]*\n",
    "\n",
    "É possível, então, criar um loop que altera a url de acordo com a página que você quer extrair as informações.\n",
    "\n",
    "É dentro desse loop que o raspador vai operar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ei, Python! Para cada número entre 0 e 38 - o 39, limite superior, não entra na conta -, repita os seguintes passos:\n",
    "for page in range(0,39):\n",
    "    # Aguarde um segundo para não sobrecarregar o site da FGV\n",
    "    time.sleep(1)\n",
    "    # Atualize a URL com o número de cada página\n",
    "    url = \"http://direitosp.fgv.br/home-professor/all/all/all?page=\" + str(page) # str(page) trasnforma o número em texto\n",
    "    # Acesse o endereço que guardamos na URL\n",
    "    response = requests.get(url)\n",
    "    # Passe tudo que você encontrar para o raspador\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Procure todos os elementos 'div' com a classe \"views-field-title\" - é lá onde está o nome do professor\n",
    "    divs = doc.findAll(\"div\", { \"class\" : \"views-field-title\" })\n",
    "    # Para cada um dos 'divs' que achamos, encontre o 'a' - é lá que estão o hiperlink e o nome do professor\n",
    "    for div in divs:\n",
    "        # Crie um dicionário para o professor\n",
    "        professor = {}\n",
    "        # Acesse a tag 'a', onde estão guardado\n",
    "        data = div.find(\"a\")\n",
    "        # Acessa o link e salva na categoria \"link\" do dicionário\n",
    "        professor[\"link\"] = \"http://direitosp.fgv.br\" + data['href']\n",
    "        # Acessa o link e salva na categoria \"nome\" do dicionário\n",
    "        professor[\"nome\"] = data.text\n",
    "        # Agora, vamos passar para o próximo elemento div, onde está salva a descrição\n",
    "        # Isso funciona porque os dois dados que quero estão um em cima do outro\n",
    "        # Note que vou usar duas vezes o método .next_sibling para 'pular' uma linha em branco que separa os dois elementos\n",
    "        data = div.next_sibling.next_sibling\n",
    "        # Acessa o texto e salva na categoria \"decsrição\" do dicionário\"\n",
    "        professor[\"descricao\"] = data.text.strip()\n",
    "        # Agora que estamos com o dicionário pronto, só preciso adicionar a entrada 'professor' na lista que definimos lá em cima\n",
    "        professores.append(professor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando como csv\n",
    "Aqui, uso o módulo Pandas para transformar a lista de dicionários lá em cima em um dataframe - parecido com uma plainlha de Excel. Depois, salvo para um arquivo .csv com o encoding adequado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ransforme em uma tabela\n",
    "df = pd.DataFrame(professores)\n",
    "# Salve em .csv\n",
    "df.to_csv(\"professores_fgv.csv\",sep=\"|\",encoding=\"UTF-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
